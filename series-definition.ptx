<section xml:id="series-definition">
  <title>Definition and Convergence of Infinite Series</title>
  <subsection xml:id="series-definition-statment">
  <definition>
    <statement>
      <p>
        If <m>\{a_n\}</m> is a sequence, then the sum of all
        infinitely many terms <m>a_n</m> is called an <term>infinite
        series</term>. We write infinite series with sigma notation.
        <me>
          \sum_{n=1}^\infty a_n
        </me>
      </p>
      <p>
        The number <m>n</m> is called the <term>index</term> and the
        numbers <m>a_n</m> are called the <term>terms</term>. If we
        want to forget the sum, we can talk about the <term>sequence
        of terms</term> <m>\{a_n\}_{n=1}^\infty</m>. Though we
        started with <m>n=1</m> in this definition, we could start
        with any integer.
      </p>
    </statement>
  </definition>
  </subsection>
  <subsection xml:id="partial-sums">
    <title>Partial-Sums and Convergence</title>
    <p>
      Unlike finite sums, we have no guarantee that this expression
      evaluates to anything. The problem of infinite series is
      precisely this: how do we add up infinitely many things? This
      isn't a problem that algebra can solve, but calculus, with the
      use of limits, can give a reasonable answer. We need to set up
      an approximation process and take the limit, just as we did for
      derivatives and integrals. The approximation process is called
      partial sums. Instead of taking the entire sum to infinity,
      let's just take a piece of finite length.
    </p>
    <definition>
      <statement>
        <p>
          The <m>n</m>th <term>partial sum</term> of an infinite
          series is the sum of the first <m>n</m> terms.
          <me>
            s_n := \sum_{k=1}^n a_k
          </me>
        </p>
      </statement>
    </definition>
    <p>
      Since these are finite sums, we can actually calculate them.
      They serve as approximations to the total infinite sum.
      Moreover, these partial sums <m>\{s_n\}_{n=1}^\infty</m> define
      a sequence. We can take the limit of the sequcne of partial
      sums. This is the limit of the approximation process, so it
      should calculate the value of the series.
    </p>
    <definition>
      <statement>
        <p>
          The value of an infinite series is the limit of the sequence
          of partial sums, if the limit exists.
          <me>
            \sum_{n=1}^\infty a_n := \lim_{n \rightarrow \infty} s_n =
            \lim_{n \rightarrow \infty} \sum_{k=1}^n a_k
          </me>
        </p>
        <p>
          If this limit exists, we call the series
          <term>convergent</term>. Otherwise, we call the series
          <term>divergent</term>.
        </p>
      </statement>
    </definition>
  </subsection>
  <subsection xml:id="series-examples">
    <title>First Convergence Examples</title>
    <example>
      <statement>
        <p>
          The first and most classical example is simply Zeno's
          paradox. If we are trying to go from <m>0</m> to <m>1</m>,
          first we travel <m>\frac{1}{2}</m>, then <m>\frac{1}{4}</m>,
          then <m>\frac{1}{8}</m>, and so on. We represent this
          paradox as an infinite sum.
          <me>
            \sum_{n=1}^\infty \frac{1}{2^n}
          </me>
        </p>
        <p>
          Let's look at the partial sums.
          <md>
            <mrow>
              s_1 \amp = \frac{1}{2}
            </mrow>
            <mrow>
              s_2 \amp = \frac{1}{2} + \frac{1}{4} = \frac{3}{4}
            </mrow>
            <mrow>
              s_3 \amp = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} =
              \frac{7}{8}
            </mrow>
            <mrow>
              s_4 \amp = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
              \frac{1}{16} = \frac{15}{16}
            </mrow>
            <mrow>
              s_5 \amp = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
              \frac{1}{16} + \frac{1}{32} = \frac{31}{32}
            </mrow>
            <mrow>
              s_6 \amp = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
              \frac{1}{16} + \frac{1}{32} + \frac{1}{64} =
              \frac{63}{64}
            </mrow>
            <mrow>
              \vdots \amp \hspace{1cm} \vdots
            </mrow>
            <intertext>
              We can generate a formula to describe the pattern.
            </intertext>
            <mrow>
              s_n \amp = \frac{2^n-1}{2n}
            </mrow>
          </md>
        </p>
        <p>
          Since we have a general expression for the partial sums, we
          can take the limit.
          <me>
            \lim_{n \rightarrow \infty} s_n = \lim_{n \rightarrow
            \infty} \frac{2^n - 1}{2n} = 1
          </me>
        </p>
        <p>
          Unsurprisingly, we get that the total distance travelled
          from <m>0</m> to <m>1</m> is simply <m>1</m> unit. This
          gives a justification for saying that we <em>can</em> travel
          an infinite number of smaller and smaller intervals, since
          all those infinitely many intervals add up to a finite
          distance. (Whether this actually soves Zeno's paradox is a
          question left for the philosophers.)
        </p>
      </statement>
    </example>
    <example>
      <statement>
        <p>
          Now consider the sum of the harmonic series. We are going
          to analyze the partial sums. We don't get a general
          formula, but we can define some lower bounds for these
          partial sums.
          <md>
            <mrow>
              \sum_{n=1}^\infty \frac{1}{n} \amp
            </mrow>
            <mrow>
              s_1 \amp = 1
            </mrow>
            <mrow>
              s_2 \amp = 1 + \frac{1}{2} = \frac{3}{2}
            </mrow>
            <mrow>
              s_3 \amp = 1 + \frac{1}{2} + \frac{1}{3}
            </mrow>
            <mrow>
              s_4 \amp = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}
              > 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{4} = 2
            </mrow>
            <intertext>
              The inequatity holds since <m>\frac{1}{3} >
              \frac{1}{4}</m> and all other terms remain the same.
            </intertext>
            <mrow>
              s_8 \amp = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}
              + \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8}
            </mrow>
            <mrow>
              \amp \hspace{1cm} > 1 + \frac{1}{2} + \frac{1}{4} +
              \frac{1}{4} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8} +
              \frac{1}{8} = \frac{5}{2}
            </mrow>
            <intertext>
              We replace all the fraction without powers of 2 in the
              demoninator with smaller terms to satify the
              inequality.
            </intertext>
            <mrow>
              s_{16} \amp > 3
            </mrow>
            <intertext>
              We can generate a lower bound for <m>s_{2^n}</m> in this
              pattern.
            </intertext>
            <mrow>
              s_{32} \amp > \frac{7}{2}
            </mrow>
            <mrow>
              s_{64} \amp > 4
            </mrow>
            <mrow>
              s_{128} \amp > \frac{9}{2}
            </mrow>
            <mrow>
              s_{256} \amp > 5
            </mrow>
          </md>
        </p>
        <p>
          Taking every second power of two gives us partial sums
          larger than the sequence of positive numbers.
          <me>
            s_{2^{2k-2}} > k \hspace{2cm} \forall k \geq 2
          </me>
        </p>
        <p>
          The lower bounds get larger and larger. The limit of the
          sequence of partial sums is larger than this limit of larger
          bounds.
          <me>
            \lim_{n \rightarrow \infty} s_n = \lim_{k \rightarrow
            \infty} s_{2^{2k-2}} \geq \lim_{k \rightarrow \infty} k =
            \infty
          </me>
        </p>
        <p>
          The harmonic series is divergent. This is something of a
          surprising result, since the harmoinc series looks similar
          to the series defining Zeno's paradox. However, the terms
          of the harmonic series are large enough to eventually add up
          to something larger than any finite number.
        </p>
      </statement>
    </example>
    <example>
      <statement>
        <p>
          Another important example is an alternating series of
          positive and negative ones.
          <md>
            <mrow>
              \sum_{n=1}^\infty (-1)^n \amp
            </mrow>
            <mrow>
              s_1 \amp = 1
            </mrow>
            <mrow>
              s_2 \amp = 1-1 = 0
            </mrow>
            <mrow>
              s_3 \amp = 1-1+1 = 1
            </mrow>
            <mrow>
              s_4 \amp = 1-1+1-1 = 0
            </mrow>
            <mrow>
              s_5 \amp = 1+1-1-1+1 = 1
            </mrow>
            <mrow>
              s_6 \amp = 1+1-1-1+1-1 = 0
            </mrow>
            <mrow>
              \vdots \amp \hspace{1cm} \vdots
            </mrow>
            <intertext>
              We can determine a pattern for even and odd terms.
            </intertext>
            <mrow>
              s_{2n} \amp = 0 \ \ \forall n \in \NN
            </mrow>
            <mrow>
              s_{2n+1} \amp = 1 \ \ \forall n \in \NN
            </mrow>
            <mrow>
              \lim_{n \rightarrow \infty} s_n \amp \hspace{1cm} DNE
            </mrow>
          </md>
        </p>
        <p>
          This series does not converge, even though it doesn't grow
          to infinity. There is simply no way to settle on a value
          when the partial sums keep switching back and forth from
          <m>0</m> to <m>1</m>.
        </p>
      </statement>
    </example>
    <example>
      <statement>
        <p>
          There are some nice examples where algebraic manipulation
          leads to reasonable partial sums. In this example (and
          similar series), the middle terms in each successive partial
          sum cancel; these series are called telescoping series.
          <md>
            <mrow>
              \sum_{n=1}^\infty \frac{1}{n(n+1)} \amp
            </mrow>
            <mrow>
              s_n \amp = \sum_{k=1}^n \frac{1}{k(k+1)} = \sum_{k=1}^n
              \frac{1}{k} - \frac{1}{k+1}
            </mrow>
            <mrow>
              \amp = \frac{1}{1} - \frac{1}{2} + \frac{1}{2} -
              \frac{1}{3} + \frac{1}{3} - \frac{1}{4} + \frac{1}{4}
              \ldots - \frac{1}{n+1}
            </mrow>
            <intertext>
              Almost all the terms conveniently cancel out, leaving
              only the first and the last.
            </intertext>
            <mrow>
              \amp = 1 - \frac{1}{n+1}
            </mrow>
            <mrow>
              \sum_{n=1}^\infty \frac{1}{n(n+1)} \amp = \lim_{n
              \rightarrow \infty} 1 - \frac{1}{n+1} = 1
            </mrow>
          </md>
        </p>
      </statement>
    </example>
    <definition>
      <statement>
        <p>
          The <term>factorial</term> of a natural number <m>n</m> is
          written <m>n!</m>. It is defined to be the product of all
          natural numbers up to and including <m>n</m>.
          <me>
            n! = (1)(2)(3)(4)(5)\ldots(n-2)(n-1)(n)
          </me>
        </p>
        <p>
          In addition, we define <m>0! = 1</m>. (Why? There are good
          reasons!)
        </p>
      </statement>
    </definition>
    <p>
      The factorial grows very rapidly. Even by the time we get to
      <m>n=40</m>, the factorial is already a ridiculously large
      number.
      <me>
        40! =815915283247897734345611269596115894272000000000
      </me>
    </p>
    <p>
      Asymptotically, the factorial grows even faster than the
      exponential.
    </p>
    <example>
      <statement>
        <p>
          Here's a series example using the factorial.
          <me>
            \begin{array}{*2{>{\displaystyle}l}} \sum_{n=0}^\infty
            \frac{1}{n!} \amp \hspace{2cm} s_0 = 1 \\[1em] s_1 = 1 +
            1 = 2 \amp \hspace{2cm} s_2 = 1 + 1 + \frac{1}{2} =
            \frac{5}{2} \\[1em] s_3 = \frac{5}{2} + \frac{1}{6} =
            \frac{16}{6} \amp \hspace{2cm} s_4 = \frac{16}{6} +
            \frac{1}{24} = \frac{61}{24} \\[1em] s_5 = \frac{61}{24} +
            \frac{1}{120} = \frac{51}{20} \amp \hspace{2cm} s_6 =
            \frac{51}{20} + \frac{1}{720} = \frac{1837}{720}
            \end{array}
          </me>
        </p>
        <p>
          It looks like these terms are growing slowly and possibly
          leveling off at some value, perhaps less than 3. We can't
          prove it now, but the value of this series is surprising.
          <me>
            \sum_{n=0}^{\infty} \frac{1}{n!} = \lim_{n \rightarrow
            \infty} s_n = e
          </me>
        </p>
        <p>
          This is another definition for the number <m>e</m>. We'll
          prove that this definition is equivalent our existing
          definitions in <xref
          ref="taylor-series-examples">Section</xref>.
        </p>
      </statement>
    </example>
    <example>
      <statement>
        <p>
          The study of values of particular infinite series is a major
          project in the history of mathematics. There are many
          interesting results, some of which are listed here for your
          curiosity.
          <md>
            <mrow>
              \pi \amp = 4 \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} =
              \frac{4}{1} - \frac{4}{3} + \frac{4}{5} - \frac{4}{7} +
              \frac{4}{9} - \ldots
            </mrow>
            <mrow>
              \pi \amp = \sqrt{12} \sum_{n=-0}^\infty
              \frac{(-1)^n}{3^n (2n+1)} = \sqrt{12} \left( 1 -
              \frac{1}{9} + \frac{1}{45} - \ldots \right)
            </mrow>
            <mrow>
              \frac{1}{\pi} \amp = \frac{2\sqrt{2}}{9801}
              \sum_{n=0}^\infty \frac{ (4n)! (1103 + 26390n)}{(n!)^4
              (396)^{4n}}
            </mrow>
            <mrow>
              \frac{1}{\pi} \amp = \frac{1}{426880 \sqrt{16005}}
              \sum_{n=0}^\infty \frac{(6n)! (13591409 + 545140134n)
              (-1)^n}{(3n)! (n!)^3 (640320)^n}
            </mrow>
            <mrow>
              \frac{\pi^4}{90} \amp = \sum_{n=1}^\infty
              \frac{1}{n^4}
            </mrow>
            <mrow>
              e \amp = \sum_{n=0}^\infty \frac{(3n)^2+1}{(3n)!}
            </mrow>
            <mrow>
              e \amp = \sum_{n=0}^\infty \frac{n^7}{877n^!}
            </mrow>
          </md>
        </p>
      </statement>
    </example>
  </subsection>
  <subsection xml:id="test-for-divergence">
    <title>The Test for Divergence</title>
    <p>
      As we have seen in the examples, it is possible to build a
      series where the terms are getting smaller and smaller and still
      end up with an infinite value. This gives some credit to the
      initial concern of Zeno's paradox, since all these smaller and
      smaller pieces may eventually add up to something infinite. One
      might have the intuition that if the terms are becoming very
      small (as with the harmonic series), the series should have a
      finite sum; the harmonic series is a counter-example to this
      intuition. However, the reverse intuition holds, as seen in the
      following result.
    </p>
    <proposition>
      <statement>
        <p>
          (The Test for Divergence) If we have an infinite series
          <me>
            \sum_{n=1}^\infty a_n
          </me>
          such that
          <me>
            \lim_{n \rightarrow a_n} \neq 0
          </me>
          then the series must diverge.
        </p>
      </statement>
    </proposition>
    <p>
      Using the test for divergence and the harmonic series example,
      we can rephrase the important relation between convergence of a
      series and the limits of the terms. For an infinite series, the
      fact that the terms tend to zero is <em>necessary</em> for
      convergence but is <em>not sufficient</em>. It is a very common
      temptation to assume the fact that the terms tend to zer is
      sufficient; be careful not to fall into this trap.
    </p>
  </subsection>
</section>
